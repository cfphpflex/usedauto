{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMYfcKeDY85K"
      },
      "source": [
        "## **Getting started**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN3wE0J4j_l9"
      },
      "source": [
        "# Advanced Vehicle Price Prediction Model\n",
        "\n",
        "## Overview\n",
        "This project implements an advanced machine learning model for predicting used vehicle prices using RandomForest,  GridSearch... . The model incorporates sophisticated feature engineering, proper data preprocessing, and robust prediction pipelines.\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "### 1. Data Preprocessing Pipeline\n",
        "The model uses a comprehensive preprocessing pipeline implemented in the `VehiclePricePredictor` class:\n",
        "\n",
        "```python\n",
        "class VehiclePricePredictor:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.feature_info = None\n",
        "        self.feature_names = None\n",
        "        self.category_mappings = {}\n",
        "```\n",
        "\n",
        "#### Key Preprocessing Steps:\n",
        "- **Data Cleaning** (`clean_data()`):\n",
        "  - Handles missing values\n",
        "  - Removes outliers (prices < $100 or > $100,000)\n",
        "  - Fills missing odometer readings with mean values\n",
        "  - Fills missing years with median values\n",
        "  - Handles missing categorical values with 'unknown'\n",
        "\n",
        "- **Feature Engineering** (`engineer_features()`):\n",
        "  - Vehicle age calculation (2024 - year)\n",
        "  - Miles per year calculation\n",
        "  - Price per mile (training only)\n",
        "  - Price per year (training only)\n",
        "  - Age-mileage interaction features\n",
        "\n",
        "- **Data Preprocessing** (`preprocess_data()`):\n",
        "  - Categorical variable standardization\n",
        "  - One-hot encoding\n",
        "  - Feature scaling\n",
        "  - Feature name preservation\n",
        "\n",
        "### 2. Model Training\n",
        "The model uses LightGBM with optimized parameters:\n",
        "\n",
        "```python\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mae',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1\n",
        "}\n",
        "```\n",
        "\n",
        "#### Training Process:\n",
        "1. Data loading and cleaning\n",
        "2. Feature engineering\n",
        "3. Train/validation split\n",
        "4. Model training with early stopping\n",
        "5. Model evaluation using MAE and R² metrics\n",
        "6. Artifact saving (model, scaler, feature info)\n",
        "\n",
        "### 3. Prediction Pipeline\n",
        "The prediction process follows these steps:\n",
        "1. Input data validation\n",
        "2. Feature preprocessing\n",
        "3. Feature engineering\n",
        "4. Model prediction\n",
        "5. Price output\n",
        "\n",
        "## Key Features\n",
        "\n",
        "### 1. Robust Feature Engineering\n",
        "- **Temporal Features**:\n",
        "  - Vehicle age\n",
        "  - Miles per year\n",
        "  - Price per year (training)\n",
        "  - Price per mile (training)\n",
        "\n",
        "- **Interaction Features**:\n",
        "  - Age-mileage interaction\n",
        "  - Manufacturer-model combinations\n",
        "\n",
        "### 2. Categorical Variable Handling\n",
        "- Standardized lowercase conversion\n",
        "- One-hot encoding\n",
        "- Category mapping preservation\n",
        "- Unknown category handling\n",
        "\n",
        "### 3. Model Persistence\n",
        "The model saves three key artifacts:\n",
        "1. `model.joblib`: The trained LightGBM model\n",
        "2. `scaler.pkl`: The StandardScaler for feature normalization\n",
        "3. `feature_info.json`: Feature names and category mappings\n",
        "\n",
        "## Usage\n",
        "\n",
        "### Training the Model\n",
        "```bash\n",
        "python src/improved_model.py\n",
        "```\n",
        "\n",
        "### Making Predictions\n",
        "```bash\n",
        "python src/predict.py\n",
        "```\n",
        "\n",
        "### Using the GUI\n",
        "```bash\n",
        "python src/gui.py\n",
        "```\n",
        "\n",
        "## Performance Metrics\n",
        "The model is evaluated using:\n",
        "- Mean Absolute Error (MAE)\n",
        "- R² Score\n",
        "- Validation set performance\n",
        "- Cross-validation results\n",
        "\n",
        "## Dependencies\n",
        "- pandas\n",
        "- numpy\n",
        "- lightgbm\n",
        "- scikit-learn\n",
        "- joblib\n",
        "- pickle\n",
        "\n",
        "## Future Improvements\n",
        "1. Hyperparameter optimization\n",
        "2. Additional feature engineering\n",
        "3. Ensemble methods\n",
        "4. Real-time price updates\n",
        "5. Market trend analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "import json\n",
        "import os\n",
        "from joblib import dump as joblib_dump\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "import os\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "HVl8DUy-3Yx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6l_jGaAef6Q"
      },
      "outputs": [],
      "source": [
        "#file list\n",
        "files = os.listdir('/content/')\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "2DP1O5Kue1ms",
        "outputId": "9cc98780-fdff-476d-9723-fd6d39075d76"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a64ea12b-a8ab-420d-bb0a-8dc72c97ffc3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a64ea12b-a8ab-420d-bb0a-8dc72c97ffc3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# upload data csv files, uncomment\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeXkrEx8egmR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "9911fff9-f78c-42c2-eae1-c98fec7059ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Multiple files found in ZIP file. Only one file per ZIP: ['vehicles.csv', '__MACOSX/._vehicles.csv']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-08e66f11ebab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load uploaded csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcardata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/vehicles.csv.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(cpn.count())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    803\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Zero files found in ZIP file {path_or_buf}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    806\u001b[0m                         \u001b[0;34m\"Multiple files found in ZIP file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                         \u001b[0;34mf\"Only one file per ZIP: {zip_names}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Multiple files found in ZIP file. Only one file per ZIP: ['vehicles.csv', '__MACOSX/._vehicles.csv']"
          ]
        }
      ],
      "source": [
        "#load uploaded csv file\n",
        "cardata = pd.read_csv('/content/vehicles.csv.zip')\n",
        "# print(cpn.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "CwK57fjCYkEV",
        "outputId": "9513bb31-41d3-4a28-9fe2-9c2b85459fea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"# cpn\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Hyundai\",\n          \"Audi\",\n          \"Lexus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Palisade SEL\",\n          \"Q3 45 S line Premium Plus\",\n          \"RX 350 RX 350\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2013,\n        \"max\": 2022,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2021,\n          2015,\n          2013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"milage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"34,742 mi.\",\n          \"9,835 mi.\",\n          \"22,372 mi.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fuel_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"E85 Flex Fuel\",\n          \"Gasoline\",\n          \"Hybrid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"engine\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"3.8L V6 24V GDI DOHC\",\n          \"2.0L I4 16V GDI DOHC Turbo\",\n          \"3.5 Liter DOHC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transmission\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"8-Speed Automatic\",\n          \"7-Speed A/T\",\n          \"6-Speed A/T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ext_col\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Moonlight Cloud\",\n          \"Glacier White Metallic\",\n          \"Black\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"int_col\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Gray\",\n          \"Black\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accident\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"None reported\",\n          \"At least 1 accident or damage reported\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"$38,005\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7a6b6921-e33a-4f53-99a6-fc76d7953c53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>model</th>\n",
              "      <th>model_year</th>\n",
              "      <th>milage</th>\n",
              "      <th>fuel_type</th>\n",
              "      <th>engine</th>\n",
              "      <th>transmission</th>\n",
              "      <th>ext_col</th>\n",
              "      <th>int_col</th>\n",
              "      <th>accident</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ford</td>\n",
              "      <td>Utility Police Interceptor Base</td>\n",
              "      <td>2013</td>\n",
              "      <td>51,000 mi.</td>\n",
              "      <td>E85 Flex Fuel</td>\n",
              "      <td>300.0HP 3.7L V6 Cylinder Engine Flex Fuel Capa...</td>\n",
              "      <td>6-Speed A/T</td>\n",
              "      <td>Black</td>\n",
              "      <td>Black</td>\n",
              "      <td>At least 1 accident or damage reported</td>\n",
              "      <td>Yes</td>\n",
              "      <td>$10,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hyundai</td>\n",
              "      <td>Palisade SEL</td>\n",
              "      <td>2021</td>\n",
              "      <td>34,742 mi.</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>3.8L V6 24V GDI DOHC</td>\n",
              "      <td>8-Speed Automatic</td>\n",
              "      <td>Moonlight Cloud</td>\n",
              "      <td>Gray</td>\n",
              "      <td>At least 1 accident or damage reported</td>\n",
              "      <td>Yes</td>\n",
              "      <td>$38,005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lexus</td>\n",
              "      <td>RX 350 RX 350</td>\n",
              "      <td>2022</td>\n",
              "      <td>22,372 mi.</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>3.5 Liter DOHC</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>Blue</td>\n",
              "      <td>Black</td>\n",
              "      <td>None reported</td>\n",
              "      <td>NaN</td>\n",
              "      <td>$54,598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INFINITI</td>\n",
              "      <td>Q50 Hybrid Sport</td>\n",
              "      <td>2015</td>\n",
              "      <td>88,900 mi.</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>354.0HP 3.5L V6 Cylinder Engine Gas/Electric H...</td>\n",
              "      <td>7-Speed A/T</td>\n",
              "      <td>Black</td>\n",
              "      <td>Black</td>\n",
              "      <td>None reported</td>\n",
              "      <td>Yes</td>\n",
              "      <td>$15,500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Audi</td>\n",
              "      <td>Q3 45 S line Premium Plus</td>\n",
              "      <td>2021</td>\n",
              "      <td>9,835 mi.</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>2.0L I4 16V GDI DOHC Turbo</td>\n",
              "      <td>8-Speed Automatic</td>\n",
              "      <td>Glacier White Metallic</td>\n",
              "      <td>Black</td>\n",
              "      <td>None reported</td>\n",
              "      <td>NaN</td>\n",
              "      <td>$34,999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a6b6921-e33a-4f53-99a6-fc76d7953c53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a6b6921-e33a-4f53-99a6-fc76d7953c53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a6b6921-e33a-4f53-99a6-fc76d7953c53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-be93c6a5-7ee7-4614-a271-12ebdeda6c95\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be93c6a5-7ee7-4614-a271-12ebdeda6c95')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-be93c6a5-7ee7-4614-a271-12ebdeda6c95 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      brand                            model  model_year      milage  \\\n",
              "0      Ford  Utility Police Interceptor Base        2013  51,000 mi.   \n",
              "1   Hyundai                     Palisade SEL        2021  34,742 mi.   \n",
              "2     Lexus                    RX 350 RX 350        2022  22,372 mi.   \n",
              "3  INFINITI                 Q50 Hybrid Sport        2015  88,900 mi.   \n",
              "4      Audi        Q3 45 S line Premium Plus        2021   9,835 mi.   \n",
              "\n",
              "       fuel_type                                             engine  \\\n",
              "0  E85 Flex Fuel  300.0HP 3.7L V6 Cylinder Engine Flex Fuel Capa...   \n",
              "1       Gasoline                               3.8L V6 24V GDI DOHC   \n",
              "2       Gasoline                                     3.5 Liter DOHC   \n",
              "3         Hybrid  354.0HP 3.5L V6 Cylinder Engine Gas/Electric H...   \n",
              "4       Gasoline                         2.0L I4 16V GDI DOHC Turbo   \n",
              "\n",
              "        transmission                 ext_col int_col  \\\n",
              "0        6-Speed A/T                   Black   Black   \n",
              "1  8-Speed Automatic         Moonlight Cloud    Gray   \n",
              "2          Automatic                    Blue   Black   \n",
              "3        7-Speed A/T                   Black   Black   \n",
              "4  8-Speed Automatic  Glacier White Metallic   Black   \n",
              "\n",
              "                                 accident clean_title    price  \n",
              "0  At least 1 accident or damage reported         Yes  $10,300  \n",
              "1  At least 1 accident or damage reported         Yes  $38,005  \n",
              "2                           None reported         NaN  $54,598  \n",
              "3                           None reported         Yes  $15,500  \n",
              "4                           None reported         NaN  $34,999  "
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Explore data\n",
        "cardata.head()\n",
        "# cpn.describe()\n",
        "# cpn.info()\n",
        "# cpn.isna().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGsnm8LLc54S"
      },
      "outputs": [],
      "source": [
        "class VehiclePricePredictor:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.feature_info = None\n",
        "        self.feature_names = None\n",
        "        self.category_mappings = {}\n",
        "\n",
        "    def clean_data(self, df, is_training=True):\n",
        "        \"\"\"Clean the dataset\"\"\"\n",
        "        # Drop rows with missing prices during training\n",
        "        if is_training:\n",
        "            df = df.dropna(subset=['price'])\n",
        "            # Filter out unreasonable prices\n",
        "            df = df[(df['price'] >= 100) & (df['price'] <= 100000)]\n",
        "\n",
        "        # Fill missing values\n",
        "        df['odometer'] = df['odometer'].fillna(df['odometer'].mean() if is_training else 50000)\n",
        "        df['year'] = df['year'].fillna(df['year'].median() if is_training else 2020)\n",
        "\n",
        "        # Fill missing categorical values with 'unknown'\n",
        "        categorical_cols = ['manufacturer', 'model', 'condition', 'fuel', 'title_status',\n",
        "                           'transmission', 'drive', 'type', 'paint_color']\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna('unknown')\n",
        "\n",
        "        return df\n",
        "\n",
        "    def engineer_features(self, df, is_training=True):\n",
        "        \"\"\"Engineer additional features\"\"\"\n",
        "        # Convert categorical columns to lowercase\n",
        "        for col in ['manufacturer', 'model', 'condition', 'fuel', 'title_status', 'transmission', 'drive', 'type', 'paint_color']:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].str.lower()\n",
        "\n",
        "        # Calculate age\n",
        "        df['age'] = 2024 - df['year']\n",
        "\n",
        "        # Calculate mileage per year\n",
        "        df['miles_per_year'] = df['odometer'] / (df['age'] + 1)\n",
        "\n",
        "        # Only calculate price-related features during training\n",
        "        if is_training:\n",
        "            df['price_per_mile'] = df['price'] / (df['odometer'] + 1)\n",
        "            df['price_per_year'] = df['price'] / (df['age'] + 1)\n",
        "\n",
        "        # Create interaction features\n",
        "        df['age_mileage'] = df['age'] * df['odometer']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess_data(self, df, is_training=True):\n",
        "        \"\"\"Preprocess the data for model training or prediction\"\"\"\n",
        "        # Convert categorical columns to lowercase\n",
        "        categorical_cols = ['manufacturer', 'model', 'condition', 'fuel', 'title_status',\n",
        "                           'transmission', 'drive', 'type', 'paint_color']\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].str.lower()\n",
        "\n",
        "        # Calculate interaction features\n",
        "        df['age_mileage'] = df['age'] * df['odometer']\n",
        "\n",
        "        # Get all possible categories for each categorical column\n",
        "        self.category_mappings = {}\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                self.category_mappings[col] = sorted(df[col].unique().tolist())\n",
        "\n",
        "        # Create dummy variables\n",
        "        dummies = pd.get_dummies(df[categorical_cols])\n",
        "\n",
        "        # Combine with numeric features\n",
        "        numeric_features = ['year', 'odometer', 'age', 'miles_per_year', 'age_mileage']\n",
        "        X = pd.concat([df[numeric_features], dummies], axis=1)\n",
        "\n",
        "        # Save feature names\n",
        "        self.feature_names = list(X.columns)\n",
        "\n",
        "        # During training, return features and target\n",
        "        if is_training:\n",
        "            y = df['price']\n",
        "            return X, y\n",
        "\n",
        "        # During prediction, ensure we have all the same features as during training\n",
        "        for col in self.feature_names:\n",
        "            if col not in X.columns:\n",
        "                X[col] = 0\n",
        "\n",
        "        # Select only the columns that were present during training\n",
        "        X = X[self.feature_names]\n",
        "\n",
        "        return X\n",
        "\n",
        "    def train(self, data):\n",
        "        \"\"\"Train the model and save artifacts\"\"\"\n",
        "        try:\n",
        "            print(\"Starting model training...\")\n",
        "\n",
        "            # Clean and engineer features\n",
        "            data = self.clean_data(data, is_training=True)\n",
        "            data = self.engineer_features(data, is_training=True)\n",
        "\n",
        "            # Prepare features\n",
        "            features, target = self.preprocess_data(data, is_training=True)\n",
        "            print(f\"Prepared features with shape: {features.shape}\")\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_val, y_train, y_val = train_test_split(\n",
        "                features, target, test_size=0.2, random_state=42\n",
        "            )\n",
        "            print(\"Split data into train and validation sets\")\n",
        "\n",
        "            # Scale features\n",
        "            self.scaler = StandardScaler()\n",
        "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "            X_val_scaled = self.scaler.transform(X_val)\n",
        "            print(\"Scaled features\")\n",
        "\n",
        "            # Train model\n",
        "            self.model = RandomForestRegressor(\n",
        "                n_estimators=100,\n",
        "                max_depth=None,\n",
        "                min_samples_split=2,\n",
        "                min_samples_leaf=1,\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            self.model.fit(X_train_scaled, y_train)\n",
        "            print(\"Trained model\")\n",
        "\n",
        "            # Evaluate model\n",
        "            val_score = np.mean(np.abs(self.model.predict(X_val_scaled) - y_val))\n",
        "            print(f\"Validation MAE: {val_score:.2f}\")\n",
        "\n",
        "            # Save feature information\n",
        "            feature_info = {\n",
        "                'feature_columns': features.columns.tolist(),\n",
        "                'numeric_features': ['year', 'odometer', 'age', 'miles_per_year', 'age_mileage'],\n",
        "                'categorical_features': [\n",
        "                    'manufacturer', 'model', 'condition', 'fuel', 'title_status',\n",
        "                    'transmission', 'drive', 'type', 'paint_color'\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            # Save artifacts\n",
        "            os.makedirs('models', exist_ok=True)\n",
        "            joblib_dump(self.model, os.path.join('models', 'model.joblib'))\n",
        "            joblib_dump(self.scaler, os.path.join('models', 'scaler.joblib'))\n",
        "            with open(os.path.join('models', 'feature_info.json'), 'w') as f:\n",
        "                json.dump(feature_info, f, indent=4)\n",
        "            print(\"Saved model artifacts\")\n",
        "\n",
        "            return val_score\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during training: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def predict(self, vehicle):\n",
        "        \"\"\"Make a price prediction for a single vehicle\"\"\"\n",
        "        # Create DataFrame from vehicle data\n",
        "        df = pd.DataFrame([vehicle])\n",
        "\n",
        "        # Clean and engineer features\n",
        "        df = self.clean_data(df, is_training=False)\n",
        "        df = self.engineer_features(df, is_training=False)\n",
        "\n",
        "        # Preprocess features\n",
        "        X = self.preprocess_data(df, is_training=False)\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = self.model.predict(X_scaled)[0]\n",
        "\n",
        "        return prediction\n",
        "\n",
        "    def save(self, directory='models'):\n",
        "        \"\"\"Save the model and artifacts\"\"\"\n",
        "        try:\n",
        "            # Create directory if it doesn't exist\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "            # Save model\n",
        "            model_path = os.path.join(directory, 'model.joblib')\n",
        "            joblib.dump(self.model, model_path)\n",
        "            print(f\"Model saved to {model_path}\")\n",
        "\n",
        "            # Save scaler\n",
        "            scaler_path = os.path.join(directory, 'scaler.joblib')\n",
        "            joblib.dump(self.scaler, scaler_path)\n",
        "            print(f\"Scaler saved to {scaler_path}\")\n",
        "\n",
        "            # Save feature info for training\n",
        "            feature_info_train = {\n",
        "                'feature_columns': self.feature_names,\n",
        "                'numeric_features': ['year', 'odometer', 'age', 'miles_per_year', 'age_mileage'],\n",
        "                'categorical_features': ['manufacturer', 'model', 'condition', 'fuel', 'title_status',\n",
        "                                       'transmission', 'drive', 'type', 'paint_color'],\n",
        "                'category_mappings': self.category_mappings\n",
        "            }\n",
        "            feature_info_train_path = os.path.join(directory, 'feature_info_train.joblib')\n",
        "            joblib.dump(feature_info_train, feature_info_train_path)\n",
        "            print(f\"Training feature info saved to {feature_info_train_path}\")\n",
        "\n",
        "            # Save feature info for prediction\n",
        "            feature_info = {\n",
        "                'feature_names': self.feature_names,\n",
        "                'category_mappings': self.category_mappings\n",
        "            }\n",
        "\n",
        "            # Save as joblib\n",
        "            feature_info_path = os.path.join(directory, 'feature_info.joblib')\n",
        "            joblib.dump(feature_info, feature_info_path)\n",
        "            print(f\"Feature info saved to {feature_info_path}\")\n",
        "\n",
        "            # Save as JSON for readability\n",
        "            feature_info_json_path = os.path.join(directory, 'feature_info.json')\n",
        "            with open(feature_info_json_path, 'w') as f:\n",
        "                json.dump(feature_info, f, indent=4)\n",
        "            print(f\"Feature info saved to {feature_info_json_path}\")\n",
        "\n",
        "            print(\"Model and artifacts saved successfully!\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving model and artifacts: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def load(self, directory='models'):\n",
        "        \"\"\"Load the model and artifacts\"\"\"\n",
        "        try:\n",
        "            # Create directory if it doesn't exist\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "            # Load model\n",
        "            model_path = os.path.join(directory, 'model.joblib')\n",
        "            if not os.path.exists(model_path):\n",
        "                raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
        "            self.model = joblib.load(model_path)\n",
        "            print(f\"Model loaded from {model_path}\")\n",
        "\n",
        "            # Load scaler\n",
        "            scaler_path = os.path.join(directory, 'scaler.joblib')\n",
        "            if not os.path.exists(scaler_path):\n",
        "                raise FileNotFoundError(f\"Scaler file not found at {scaler_path}\")\n",
        "            self.scaler = joblib.load(scaler_path)\n",
        "            print(f\"Scaler loaded from {scaler_path}\")\n",
        "\n",
        "            # Load feature info\n",
        "            feature_info_path = os.path.join(directory, 'feature_info.json')\n",
        "            if not os.path.exists(feature_info_path):\n",
        "                raise FileNotFoundError(f\"Feature info file not found at {feature_info_path}\")\n",
        "            with open(feature_info_path, 'r') as f:\n",
        "                self.feature_info = json.load(f)\n",
        "            print(f\"Feature info loaded from {feature_info_path}\")\n",
        "\n",
        "            # Extract feature names and category mappings\n",
        "            self.feature_names = self.feature_info['feature_columns']\n",
        "            self.category_mappings = self.feature_info.get('category_mappings', {})\n",
        "\n",
        "            print(\"Model and artifacts loaded successfully!\")\n",
        "            return self.model, self.scaler, self.feature_info\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model and artifacts: {str(e)}\")\n",
        "            return None, None, None\n",
        "\n",
        "    def prepare_features(self, data, is_training=False):\n",
        "        \"\"\"Prepare features for model training or prediction\"\"\"\n",
        "        try:\n",
        "            # Convert to DataFrame if dict\n",
        "            if isinstance(data, dict):\n",
        "                data = pd.DataFrame([data])\n",
        "\n",
        "            # Convert categorical columns to lowercase\n",
        "            categorical_features = [\n",
        "                'manufacturer', 'model', 'condition', 'fuel', 'title_status',\n",
        "                'transmission', 'drive', 'type', 'paint_color'\n",
        "            ]\n",
        "            numeric_features = ['year', 'odometer']\n",
        "\n",
        "            # Fill missing values\n",
        "            for col in numeric_features:\n",
        "                if col not in data.columns:\n",
        "                    data[col] = 50000 if col == 'odometer' else 2020\n",
        "                data[col] = data[col].fillna(50000 if col == 'odometer' else 2020)\n",
        "\n",
        "            for col in categorical_features:\n",
        "                if col in data.columns:\n",
        "                    data[col] = data[col].str.lower() if data[col].dtype == 'object' else data[col]\n",
        "                    data[col] = data[col].fillna('unknown')\n",
        "                else:\n",
        "                    data[col] = 'unknown'\n",
        "\n",
        "            # Calculate derived features\n",
        "            current_year = datetime.now().year\n",
        "            data['age'] = current_year - data['year']\n",
        "            data['miles_per_year'] = data['odometer'] / data['age'].replace(0, 1)  # Avoid division by zero\n",
        "            data['age_mileage'] = data['age'] * data['miles_per_year']\n",
        "\n",
        "            # Create dummy variables for categorical features\n",
        "            dummy_features = pd.get_dummies(data[categorical_features], prefix=categorical_features)\n",
        "\n",
        "            # Combine numeric and dummy features\n",
        "            numeric_data = data[['year', 'odometer', 'age', 'miles_per_year', 'age_mileage']]\n",
        "            features = pd.concat([numeric_data, dummy_features], axis=1)\n",
        "\n",
        "            # Ensure all features are float type\n",
        "            features = features.astype(float)\n",
        "\n",
        "            print(f\"Prepared features shape: {features.shape}\")\n",
        "            return features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing features: {str(e)}\")\n",
        "            raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alYrAyM6edEw"
      },
      "outputs": [],
      "source": [
        "def load_and_explore_data():\n",
        "    \"\"\"Load and clean the dataset\"\"\"\n",
        "    # Load data with a reasonable limit\n",
        "    df = pd.read_csv('data/vehicles.csv', nrows=200000)\n",
        "\n",
        "    # Keep only relevant columns\n",
        "    columns_to_keep = ['year', 'manufacturer', 'model', 'condition', 'odometer',\n",
        "                      'fuel', 'title_status', 'transmission', 'drive', 'type',\n",
        "                      'paint_color', 'price']\n",
        "    df = df[columns_to_keep]\n",
        "\n",
        "    # Basic cleaning\n",
        "    df = df.dropna(subset=['price'])  # Drop rows with missing prices\n",
        "    df = df[(df['price'] >= 100) & (df['price'] <= 100000)]  # Filter price range\n",
        "\n",
        "    # Convert categorical columns to lowercase\n",
        "    categorical_cols = ['manufacturer', 'model', 'condition', 'fuel', 'title_status',\n",
        "                       'transmission', 'drive', 'type', 'paint_color']\n",
        "    for col in categorical_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].str.lower()\n",
        "\n",
        "    # Fill missing values\n",
        "    df['odometer'] = df['odometer'].fillna(df['odometer'].mean())\n",
        "    df['year'] = df['year'].fillna(df['year'].median())\n",
        "    for col in categorical_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna('unknown')\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl229f3qZkFN"
      },
      "outputs": [],
      "source": [
        "def prepare_features(data, is_training=True):\n",
        "    \"\"\"\n",
        "    Prepare features for model training or prediction.\n",
        "    Args:\n",
        "        data: DataFrame for training or dict/Series for prediction\n",
        "        is_training: bool, whether preparing for training or prediction\n",
        "    \"\"\"\n",
        "    if is_training:\n",
        "        df = data.copy()\n",
        "        # Drop rows with missing prices for training data\n",
        "        df = df.dropna(subset=['price'])\n",
        "\n",
        "        # Fill missing values\n",
        "        df['odometer'] = df['odometer'].fillna(df['odometer'].mean())\n",
        "        df['year'] = df['year'].fillna(df['year'].median())\n",
        "\n",
        "        numeric_features = ['year', 'odometer']\n",
        "        categorical_features = ['manufacturer', 'model', 'condition', 'fuel',\n",
        "                              'title_status', 'transmission', 'drive', 'type',\n",
        "                              'paint_color']\n",
        "\n",
        "        # Convert categorical columns to lowercase and fill missing values\n",
        "        for col in categorical_features:\n",
        "            df[col] = df[col].str.lower()\n",
        "            df[col] = df[col].fillna('unknown')\n",
        "\n",
        "        # Calculate derived features\n",
        "        current_year = datetime.now().year\n",
        "        df['age'] = current_year - df['year']\n",
        "        df['miles_per_year'] = df['odometer'] / df['age'].clip(lower=0.1)\n",
        "        df['age_mileage'] = df['age'] * df['odometer']\n",
        "\n",
        "        numeric_features.extend(['age', 'miles_per_year', 'age_mileage'])\n",
        "\n",
        "        # Create dummy variables for categorical features\n",
        "        dummies = pd.get_dummies(df[categorical_features], prefix=categorical_features)\n",
        "\n",
        "        # Store category mapping\n",
        "        category_mapping = {}\n",
        "        for col in categorical_features:\n",
        "            category_mapping[col] = df[col].unique().tolist()\n",
        "\n",
        "        # Combine features\n",
        "        features = pd.concat([df[numeric_features], dummies], axis=1)\n",
        "\n",
        "        # Store feature information\n",
        "        feature_info = {\n",
        "            'numeric_features': numeric_features,\n",
        "            'categorical_features': categorical_features,\n",
        "            'category_mapping': category_mapping,\n",
        "            'all_features': features.columns.tolist()\n",
        "        }\n",
        "\n",
        "        return features, df['price'], feature_info\n",
        "\n",
        "    else:\n",
        "        # Handle single vehicle prediction\n",
        "        if isinstance(data, dict):\n",
        "            df = pd.DataFrame([data])\n",
        "        else:\n",
        "            df = pd.DataFrame([data.to_dict()])\n",
        "\n",
        "        # Load feature info\n",
        "        with open('models/feature_info.json', 'r') as f:\n",
        "            feature_info = json.load(f)\n",
        "\n",
        "        numeric_features = feature_info['numeric_features']\n",
        "        categorical_features = feature_info['categorical_features']\n",
        "        category_mapping = feature_info['category_mapping']\n",
        "        all_features = feature_info['all_features']\n",
        "\n",
        "        # Convert categorical columns to lowercase\n",
        "        for col in categorical_features:\n",
        "            df[col] = df[col].str.lower()\n",
        "            df[col] = df[col].fillna('unknown')\n",
        "\n",
        "        # Calculate derived features\n",
        "        current_year = datetime.now().year\n",
        "        df['age'] = current_year - df['year']\n",
        "        df['miles_per_year'] = df['odometer'] / df['age'].clip(lower=0.1)\n",
        "        df['age_mileage'] = df['age'] * df['odometer']\n",
        "\n",
        "        # Create dummy variables\n",
        "        dummies = pd.get_dummies(df[categorical_features], prefix=categorical_features)\n",
        "\n",
        "        # Ensure all training features are present\n",
        "        for feature in all_features:\n",
        "            if feature not in dummies.columns and feature not in numeric_features:\n",
        "                dummies[feature] = 0\n",
        "\n",
        "        # Combine features\n",
        "        features = pd.concat([df[numeric_features], dummies[all_features[len(numeric_features):]]], axis=1)\n",
        "\n",
        "        return features[all_features]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kgJF3xmg7vM"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Train a RandomForest model.\"\"\"\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    val_score = np.mean(np.abs(model.predict(X_val) - y_val))\n",
        "    print(f\"Validation MAE: {val_score:.2f}\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_YBOh2hgghz"
      },
      "outputs": [],
      "source": [
        "def save_model(model, scaler, feature_info):\n",
        "    \"\"\"Save the model, scaler, and feature information.\"\"\"\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "\n",
        "    # Save model using joblib\n",
        "    joblib_dump(model, 'models/model.joblib')\n",
        "\n",
        "    # Save scaler using joblib\n",
        "    joblib_dump(scaler, 'models/scaler.joblib')\n",
        "\n",
        "    # Save feature information\n",
        "    with open('models/feature_info.json', 'w') as f:\n",
        "        json.dump(feature_info, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSLxGradqVix"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Main function to train and save the model.\"\"\"\n",
        "    print(\"Loading and preparing data...\")\n",
        "    df = load_and_explore_data()\n",
        "\n",
        "    print(\"Engineering features...\")\n",
        "    X, y, feature_info = prepare_features(df, is_training=True)\n",
        "\n",
        "    print(\"Splitting data...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(\"Scaling features...\")\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(\"Training model...\")\n",
        "    model = train_model(X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "\n",
        "    print(\"Saving model and artifacts...\")\n",
        "    save_model(model, scaler, feature_info)\n",
        "\n",
        "    # Test prediction\n",
        "    test_vehicle = {\n",
        "        'year': 2020,\n",
        "        'manufacturer': 'tesla',\n",
        "        'model': 'model 3',\n",
        "        'condition': 'excellent',\n",
        "        'odometer': 25000,\n",
        "        'fuel': 'electric',\n",
        "        'title_status': 'clean',\n",
        "        'transmission': 'automatic',\n",
        "        'drive': 'rwd',\n",
        "        'type': 'sedan',\n",
        "        'paint_color': 'red'\n",
        "    }\n",
        "\n",
        "    X_pred = prepare_features(test_vehicle, is_training=False)\n",
        "    X_pred_scaled = scaler.transform(X_pred)\n",
        "    prediction = model.predict(X_pred_scaled)[0]\n",
        "\n",
        "    print(f\"\\nPredicted price for test vehicle: ${prediction:,.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}